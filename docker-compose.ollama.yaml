name: ollama-starter

volumes:
    ollama:
        name: ollama
    open-webui:
        name: open-webui

services:
    ollama:
        container_name: ollama
        image: ollama/ollama
        restart: always
        # deploy:
        #     resources:
        #         reservations:
        #             devices:
        #                 - driver: nvidia
        #                   count: all
        #                   capabilities:
        #                       - gpu
        volumes:
            - ollama:/root/.ollama
        ports:
            - 11434:11434
        tty: true
        environment:
            - "OLLAMA_DEBUG=1"
    open-webui:
        container_name: open-webui
        image: ghcr.io/open-webui/open-webui:main
        restart: always
        depends_on:
            - ollama
        volumes:
            - open-webui:/app/backend/data
        ports:
            - 3000:8080
        extra_hosts:
          - host.docker.internal:host-gateway
        environment:
          - 'OLLAMA_BASE_URL=http://ollama:11434'
          - 'WEBUI_SECRET_KEY='